{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dab04801",
   "metadata": {},
   "outputs": [],
   "source": [
    "BostonTrain = pd.read_csv(\"boston_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "154a6646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     crim    zn  indus  chas    nox     rm    age     dis  rad  tax  \\\n",
       "0   3  0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242   \n",
       "1   6  0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222   \n",
       "2   8  0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311   \n",
       "3   9  0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311   \n",
       "4  10  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311   \n",
       "\n",
       "   ptratio   black  lstat  \n",
       "0     17.8  392.83   4.03  \n",
       "1     18.7  394.12   5.21  \n",
       "2     15.2  396.90  19.15  \n",
       "3     15.2  386.63  29.93  \n",
       "4     15.2  386.71  17.10  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BostonTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d3c0a49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173 entries, 0 to 172\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   ID       173 non-null    int64  \n",
      " 1   crim     173 non-null    float64\n",
      " 2   zn       173 non-null    float64\n",
      " 3   indus    173 non-null    float64\n",
      " 4   chas     173 non-null    int64  \n",
      " 5   nox      173 non-null    float64\n",
      " 6   rm       173 non-null    float64\n",
      " 7   age      173 non-null    float64\n",
      " 8   dis      173 non-null    float64\n",
      " 9   rad      173 non-null    int64  \n",
      " 10  tax      173 non-null    int64  \n",
      " 11  ptratio  173 non-null    float64\n",
      " 12  black    173 non-null    float64\n",
      " 13  lstat    173 non-null    float64\n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 19.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>258.404624</td>\n",
       "      <td>4.100862</td>\n",
       "      <td>12.661850</td>\n",
       "      <td>10.835145</td>\n",
       "      <td>0.086705</td>\n",
       "      <td>0.549981</td>\n",
       "      <td>6.321237</td>\n",
       "      <td>69.245665</td>\n",
       "      <td>3.958865</td>\n",
       "      <td>9.387283</td>\n",
       "      <td>406.231214</td>\n",
       "      <td>18.469942</td>\n",
       "      <td>351.299711</td>\n",
       "      <td>12.917977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>143.289788</td>\n",
       "      <td>10.607761</td>\n",
       "      <td>24.536277</td>\n",
       "      <td>6.596488</td>\n",
       "      <td>0.282219</td>\n",
       "      <td>0.117826</td>\n",
       "      <td>0.700621</td>\n",
       "      <td>28.248244</td>\n",
       "      <td>2.324131</td>\n",
       "      <td>8.662621</td>\n",
       "      <td>164.480626</td>\n",
       "      <td>2.196196</td>\n",
       "      <td>99.781464</td>\n",
       "      <td>7.293408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.013810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>4.138000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.178100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.082210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>5.895000</td>\n",
       "      <td>42.800000</td>\n",
       "      <td>2.010700</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>371.720000</td>\n",
       "      <td>6.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>268.000000</td>\n",
       "      <td>0.251990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.223000</td>\n",
       "      <td>79.200000</td>\n",
       "      <td>3.421100</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>390.070000</td>\n",
       "      <td>12.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>381.000000</td>\n",
       "      <td>3.673670</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.674000</td>\n",
       "      <td>94.600000</td>\n",
       "      <td>5.400700</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.060000</td>\n",
       "      <td>17.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>505.000000</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>34.370000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID        crim          zn       indus        chas         nox  \\\n",
       "count  173.000000  173.000000  173.000000  173.000000  173.000000  173.000000   \n",
       "mean   258.404624    4.100862   12.661850   10.835145    0.086705    0.549981   \n",
       "std    143.289788   10.607761   24.536277    6.596488    0.282219    0.117826   \n",
       "min      3.000000    0.013810    0.000000    0.460000    0.000000    0.392000   \n",
       "25%    136.000000    0.082210    0.000000    5.320000    0.000000    0.447000   \n",
       "50%    268.000000    0.251990    0.000000    8.560000    0.000000    0.538000   \n",
       "75%    381.000000    3.673670   20.000000   18.100000    0.000000    0.624000   \n",
       "max    505.000000   88.976200   95.000000   27.740000    1.000000    0.871000   \n",
       "\n",
       "               rm         age         dis         rad         tax     ptratio  \\\n",
       "count  173.000000  173.000000  173.000000  173.000000  173.000000  173.000000   \n",
       "mean     6.321237   69.245665    3.958865    9.387283  406.231214   18.469942   \n",
       "std      0.700621   28.248244    2.324131    8.662621  164.480626    2.196196   \n",
       "min      4.138000    2.900000    1.178100    1.000000  187.000000   12.600000   \n",
       "25%      5.895000   42.800000    2.010700    4.000000  279.000000   17.000000   \n",
       "50%      6.223000   79.200000    3.421100    5.000000  330.000000   19.100000   \n",
       "75%      6.674000   94.600000    5.400700   24.000000  666.000000   20.200000   \n",
       "max      8.780000  100.000000   12.126500   24.000000  711.000000   22.000000   \n",
       "\n",
       "            black       lstat  \n",
       "count  173.000000  173.000000  \n",
       "mean   351.299711   12.917977  \n",
       "std     99.781464    7.293408  \n",
       "min      0.320000    1.920000  \n",
       "25%    371.720000    6.870000  \n",
       "50%    390.070000   12.120000  \n",
       "75%    396.060000   17.210000  \n",
       "max    396.900000   34.370000  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BostonTrain.info()\n",
    "BostonTrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = BostonTrain.iloc[:,1:-1].values\n",
    "Y = BostonTrain.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a0f33884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7121414b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 12)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bab2136f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d65ab0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "413c617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4a2c85ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karan\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,985</span> (39.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,985\u001b[0m (39.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,985</span> (39.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,985\u001b[0m (39.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=X_train[0].shape))\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(1,activation = 'linear'))\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b6ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 2951.3308 - mae: 32.5650 - val_loss: 46.0186 - val_mae: 5.1979\n",
      "Epoch 2/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 67.5314 - mae: 5.6869 - val_loss: 41.4913 - val_mae: 4.9207\n",
      "Epoch 3/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 52.5201 - mae: 5.5117 - val_loss: 71.8471 - val_mae: 5.7626\n",
      "Epoch 4/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 38.6872 - mae: 5.1765 - val_loss: 42.2740 - val_mae: 4.4288\n",
      "Epoch 5/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 58.2322 - mae: 5.9806 - val_loss: 89.2668 - val_mae: 8.0203\n",
      "Epoch 6/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 36.5957 - mae: 4.5637 - val_loss: 217.6280 - val_mae: 13.3243\n",
      "Epoch 7/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 62.6782 - mae: 6.3059 - val_loss: 44.6422 - val_mae: 4.5882\n",
      "Epoch 8/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 39.3952 - mae: 4.7370 - val_loss: 47.5902 - val_mae: 4.5394\n",
      "Epoch 9/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 43.7142 - mae: 5.0019 - val_loss: 73.8905 - val_mae: 6.6065\n",
      "Epoch 10/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 104.6111 - mae: 7.5744 - val_loss: 76.4375 - val_mae: 7.0708\n",
      "Epoch 11/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 46.6214 - mae: 5.4843 - val_loss: 64.9268 - val_mae: 6.8441\n",
      "Epoch 12/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 56.9186 - mae: 6.3596 - val_loss: 34.8377 - val_mae: 4.2339\n",
      "Epoch 13/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 44.6462 - mae: 5.2528 - val_loss: 54.2672 - val_mae: 6.0251\n",
      "Epoch 14/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 42.3743 - mae: 5.0706 - val_loss: 50.9722 - val_mae: 5.3479\n",
      "Epoch 15/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 63.6966 - mae: 6.0871 - val_loss: 89.8120 - val_mae: 6.7103\n",
      "Epoch 16/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 46.2534 - mae: 5.1655 - val_loss: 84.4865 - val_mae: 7.6622\n",
      "Epoch 17/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 39.2609 - mae: 4.9018 - val_loss: 115.7101 - val_mae: 9.8746\n",
      "Epoch 18/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 51.3536 - mae: 5.1623 - val_loss: 76.1700 - val_mae: 7.9276\n",
      "Epoch 19/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 44.9060 - mae: 5.1917 - val_loss: 39.6753 - val_mae: 4.4494\n",
      "Epoch 20/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 33.6536 - mae: 4.5759 - val_loss: 44.2951 - val_mae: 5.1153\n",
      "Epoch 21/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 49.1680 - mae: 5.1071 - val_loss: 41.5369 - val_mae: 5.2330\n",
      "Epoch 22/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 35.6682 - mae: 4.5451 - val_loss: 40.1450 - val_mae: 4.4411\n",
      "Epoch 23/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 38.9837 - mae: 4.6541 - val_loss: 46.3599 - val_mae: 4.8597\n",
      "Epoch 24/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 50.4077 - mae: 5.5270 - val_loss: 41.9217 - val_mae: 5.0325\n",
      "Epoch 25/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 27.4264 - mae: 3.8686 - val_loss: 46.2318 - val_mae: 5.4655\n",
      "Epoch 26/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 30.0441 - mae: 4.1512 - val_loss: 38.3389 - val_mae: 4.2766\n",
      "Epoch 27/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 37.0671 - mae: 4.7829 - val_loss: 37.9644 - val_mae: 4.2060\n",
      "Epoch 28/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 34.3422 - mae: 4.8108 - val_loss: 66.5780 - val_mae: 6.2545\n",
      "Epoch 29/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 39.0387 - mae: 4.5656 - val_loss: 52.5372 - val_mae: 5.0879\n",
      "Epoch 30/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 41.6021 - mae: 4.9937 - val_loss: 48.5116 - val_mae: 5.8456\n",
      "Epoch 31/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 45.6070 - mae: 5.4170 - val_loss: 37.8627 - val_mae: 4.3081\n",
      "Epoch 32/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 18.6285 - mae: 3.3051 - val_loss: 64.7533 - val_mae: 5.9234\n",
      "Epoch 33/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 25.9447 - mae: 3.9403 - val_loss: 76.6195 - val_mae: 6.4439\n",
      "Epoch 34/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 26.4941 - mae: 3.8454 - val_loss: 55.5462 - val_mae: 5.2148\n",
      "Epoch 35/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 27.5144 - mae: 4.2388 - val_loss: 37.6067 - val_mae: 4.1676\n",
      "Epoch 36/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 28.0808 - mae: 4.1351 - val_loss: 64.0667 - val_mae: 6.5921\n",
      "Epoch 37/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 25.5966 - mae: 3.7784 - val_loss: 69.7697 - val_mae: 6.4070\n",
      "Epoch 38/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 44.2793 - mae: 5.4206 - val_loss: 96.8627 - val_mae: 8.4259\n",
      "Epoch 39/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 35.6594 - mae: 4.8493 - val_loss: 40.2011 - val_mae: 4.6791\n",
      "Epoch 40/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 27.1605 - mae: 3.4269 - val_loss: 45.4236 - val_mae: 4.5007\n",
      "Epoch 41/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 17.3901 - mae: 3.1911 - val_loss: 61.9711 - val_mae: 6.9486\n",
      "Epoch 42/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 40.3106 - mae: 5.2238 - val_loss: 36.8964 - val_mae: 4.2937\n",
      "Epoch 43/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 31.2193 - mae: 4.4756 - val_loss: 45.5032 - val_mae: 4.9400\n",
      "Epoch 44/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 26.2137 - mae: 4.2039 - val_loss: 71.6609 - val_mae: 7.6222\n",
      "Epoch 45/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 24.1448 - mae: 3.9888 - val_loss: 38.8382 - val_mae: 4.1922\n",
      "Epoch 46/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 26.0290 - mae: 3.7241 - val_loss: 44.7690 - val_mae: 5.2120\n",
      "Epoch 47/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 22.0854 - mae: 3.5790 - val_loss: 40.4694 - val_mae: 5.0677\n",
      "Epoch 48/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 25.7179 - mae: 3.9144 - val_loss: 48.7913 - val_mae: 5.6539\n",
      "Epoch 49/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 27.4906 - mae: 3.8699 - val_loss: 58.0469 - val_mae: 5.6584\n",
      "Epoch 50/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 41.0606 - mae: 4.8403 - val_loss: 37.8902 - val_mae: 4.5400\n",
      "Epoch 51/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 23.2389 - mae: 3.8614 - val_loss: 37.0444 - val_mae: 4.2984\n",
      "Epoch 52/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 23.5439 - mae: 3.6101 - val_loss: 37.5804 - val_mae: 4.1944\n",
      "Epoch 53/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 19.7025 - mae: 3.2145 - val_loss: 38.1480 - val_mae: 4.3092\n",
      "Epoch 54/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 18.8869 - mae: 3.0924 - val_loss: 38.8853 - val_mae: 4.2495\n",
      "Epoch 55/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 23.4928 - mae: 3.5240 - val_loss: 37.2953 - val_mae: 4.2426\n",
      "Epoch 56/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 22.7808 - mae: 3.7114 - val_loss: 39.1037 - val_mae: 4.3454\n",
      "Epoch 57/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 33.5808 - mae: 4.1902 - val_loss: 46.0723 - val_mae: 4.8251\n",
      "Epoch 58/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 28.3482 - mae: 4.0086 - val_loss: 37.1915 - val_mae: 4.4177\n",
      "Epoch 59/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.9296 - mae: 3.5602 - val_loss: 46.6271 - val_mae: 5.6379\n",
      "Epoch 60/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.8102 - mae: 3.8537 - val_loss: 50.2712 - val_mae: 5.0918\n",
      "Epoch 61/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 29.9264 - mae: 4.3947 - val_loss: 43.4827 - val_mae: 4.4468\n",
      "Epoch 62/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 28.8718 - mae: 4.2333 - val_loss: 40.8278 - val_mae: 5.0748\n",
      "Epoch 63/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 26.2752 - mae: 3.9212 - val_loss: 36.9800 - val_mae: 4.4706\n",
      "Epoch 64/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.3149 - mae: 3.4439 - val_loss: 40.3401 - val_mae: 4.8902\n",
      "Epoch 65/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 18.6643 - mae: 2.9766 - val_loss: 36.5620 - val_mae: 4.3756\n",
      "Epoch 66/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.0156 - mae: 3.4622 - val_loss: 36.9930 - val_mae: 4.3049\n",
      "Epoch 67/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 29.3411 - mae: 3.9037 - val_loss: 39.1512 - val_mae: 4.5112\n",
      "Epoch 68/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 21.4836 - mae: 3.4226 - val_loss: 47.2189 - val_mae: 4.5763\n",
      "Epoch 69/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 23.2186 - mae: 3.7235 - val_loss: 38.7572 - val_mae: 4.6608\n",
      "Epoch 70/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 25.2953 - mae: 3.8742 - val_loss: 40.4282 - val_mae: 4.5271\n",
      "Epoch 71/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 16.5501 - mae: 3.0167 - val_loss: 43.7497 - val_mae: 4.4326\n",
      "Epoch 72/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 26.2761 - mae: 3.7850 - val_loss: 39.2969 - val_mae: 4.2649\n",
      "Epoch 73/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 22.7340 - mae: 3.6638 - val_loss: 37.8863 - val_mae: 4.2799\n",
      "Epoch 74/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 20.8532 - mae: 3.2989 - val_loss: 52.5269 - val_mae: 6.1399\n",
      "Epoch 75/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 28.8484 - mae: 3.8173 - val_loss: 45.2720 - val_mae: 4.6199\n",
      "Epoch 76/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.6372 - mae: 3.5703 - val_loss: 38.1295 - val_mae: 4.7050\n",
      "Epoch 77/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 20.5269 - mae: 3.5019 - val_loss: 38.5270 - val_mae: 4.3948\n",
      "Epoch 78/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 18.6605 - mae: 3.2892 - val_loss: 42.8584 - val_mae: 4.3783\n",
      "Epoch 79/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.7209 - mae: 3.4478 - val_loss: 36.2518 - val_mae: 4.2202\n",
      "Epoch 80/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.0763 - mae: 3.5631 - val_loss: 41.1184 - val_mae: 4.9976\n",
      "Epoch 81/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 23.0612 - mae: 3.4621 - val_loss: 36.7355 - val_mae: 4.2281\n",
      "Epoch 82/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.4634 - mae: 3.7409 - val_loss: 41.0973 - val_mae: 5.1020\n",
      "Epoch 83/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 19.5944 - mae: 3.4371 - val_loss: 36.7323 - val_mae: 4.1857\n",
      "Epoch 84/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 20.6636 - mae: 3.5790 - val_loss: 39.2049 - val_mae: 4.6707\n",
      "Epoch 85/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.4891 - mae: 3.7801 - val_loss: 44.0267 - val_mae: 5.3561\n",
      "Epoch 86/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 22.0072 - mae: 3.5619 - val_loss: 38.8205 - val_mae: 4.3951\n",
      "Epoch 87/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.5801 - mae: 3.3495 - val_loss: 46.9016 - val_mae: 4.8711\n",
      "Epoch 88/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 18.0420 - mae: 3.3136 - val_loss: 38.4878 - val_mae: 4.1816\n",
      "Epoch 89/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 17.6440 - mae: 2.9567 - val_loss: 37.2256 - val_mae: 4.1367\n",
      "Epoch 90/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 20.1463 - mae: 3.3030 - val_loss: 41.2232 - val_mae: 5.0404\n",
      "Epoch 91/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 18.1685 - mae: 2.9922 - val_loss: 38.5154 - val_mae: 4.5431\n",
      "Epoch 92/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 17.7223 - mae: 3.4317 - val_loss: 40.0599 - val_mae: 4.1713\n",
      "Epoch 93/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 16.4063 - mae: 3.3521 - val_loss: 41.1679 - val_mae: 4.2964\n",
      "Epoch 94/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 17.7725 - mae: 3.2582 - val_loss: 37.8237 - val_mae: 4.0956\n",
      "Epoch 95/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.7555 - mae: 3.3642 - val_loss: 41.1169 - val_mae: 4.9257\n",
      "Epoch 96/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 20.3958 - mae: 3.5041 - val_loss: 36.3538 - val_mae: 4.1170\n",
      "Epoch 97/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 18.8333 - mae: 3.2398 - val_loss: 38.3877 - val_mae: 4.1894\n",
      "Epoch 98/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 25.5012 - mae: 3.7337 - val_loss: 37.4663 - val_mae: 4.4334\n",
      "Epoch 99/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 15.3634 - mae: 2.9877 - val_loss: 36.8363 - val_mae: 4.5535\n",
      "Epoch 100/100\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 17.7950 - mae: 3.1893 - val_loss: 38.4863 - val_mae: 4.2956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d41dbcfa50>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 100, batch_size = 1, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e95c7c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.8392e-01, 0.0000e+00, 7.3800e+00, 0.0000e+00, 4.9300e-01,\n",
       "       5.7080e+00, 7.4300e+01, 4.7211e+00, 5.0000e+00, 2.8700e+02,\n",
       "       1.9600e+01, 3.9113e+02])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5c9dcf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Value:  11.74\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "Predicted Value:  10.084987\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Value: \", y_test[8])\n",
    "sample = np.array([X_test[8]])\n",
    "print(\"Predicted Value: \", model.predict(sample)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Mean Squared Error (MSE): 28.54005048113393\n",
      "Mean Absolute Error (MAE): 3.7245094729832244\n",
      "R² Score: 0.4725360096653961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_true = y_test.values if hasattr(y_test, 'values') else y_test\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R² Score:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
